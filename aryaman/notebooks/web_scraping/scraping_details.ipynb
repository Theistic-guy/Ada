{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from pprint import pprint\n",
    "from selenium import webdriver\n",
    "from pathlib import Path\n",
    "import time\n",
    "import random\n",
    "from itertools import repeat\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "# from selenium.webdriver.remote.remote_connection import LOGGER\n",
    "# LOGGER.setLevel(logging.WARNING)\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading\n",
    "import re\n",
    "import csv\n",
    "import itertools\n",
    "import ast\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    filename='scraping.log',\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_unscraped_iter(products_links_df,scraped_details_df):\n",
    "    return list(products_links_df[~(products_links_df['ASIN'].isin(scraped_details_df['ASIN']))].itertuples(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.read_csv(r'aryaman/csv/categories_and_products/products.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "webdriver_path = \"..\\chromedriver.exe\"\n",
    "cService = webdriver.ChromeService(executable_path=webdriver_path)\n",
    "# chrome_options = Options()\n",
    "# chrome_options.add_experimental_option(\"detach\",True)\n",
    "driver = webdriver.Chrome(service=cService)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('scraping_details.csv','w',newline='',encoding='utf-8') as file:\n",
    "#     writer = csv.DictWriter(file,fieldnames=['ASIN', 'Images', 'title', 'productOverview', 'featureBullets', 'stars','ratings', 'listPrice', 'salePrice'])\n",
    "#     writer.writeheader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({'blacklisted_asins':[]}).to_csv('Blacklisted_ASINs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({\"ASIN\":[],\"star_rating\":[],\"ratings\":[],\"featureBullets\":[],\"Overview\":[],\"listPrice\":[]}).to_csv('MissingDetailsChart.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_details_df = pd.read_csv('scraping_details.csv',encoding='utf-8')\n",
    "products_links = products[['ASIN','Product Link']]\n",
    "products_links.reset_index(inplace=True,drop=True)\n",
    "blacklisted_asins = (pd.read_csv('Blacklisted_ASINs.csv'))['blacklisted_asins'].tolist()\n",
    "missing_details_df = pd.read_csv('MissingDetailsChart.csv')\n",
    "no_of_items_to_scrape = 1000\n",
    "how_many_done_checkpoint = 0\n",
    "with open('scraping_details.csv','a',newline='',encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file,fieldnames=['ASIN', 'Images', 'title', 'productOverview', 'featureBullets', 'stars','ratings', 'listPrice', 'salePrice'])\n",
    "    iterator_to_loop = filter_unscraped_iter(products_links,scraped_details_df)\n",
    "    for link in iterator_to_loop:\n",
    "        if link.ASIN in blacklisted_asins:\n",
    "            continue\n",
    "        driver.get(link._1)\n",
    "        time.sleep(1)\n",
    "        missing_details_dict = {'ASIN':link.ASIN,'star_rating':False,'ratings':False,'featureBullets':False,'Overview':False}\n",
    "        is_any_detail_missing = False\n",
    "        try:\n",
    "            img_src = driver.find_element(By.CSS_SELECTOR,\"#imgTagWrapperId img\").get_attribute(\"src\")\n",
    "            if len(img_src) == 0:\n",
    "                logging.critical(f\"no img src obtained : {link.ASIN} - {link._1}\")\n",
    "                raise ValueError\n",
    "                \n",
    "            title = driver.find_element(By.CSS_SELECTOR,\"#productTitle\").text\n",
    "            if len(title) == 0:\n",
    "                logging.critical(f\"no title extracted : {link.ASIN} - {link._1}\")\n",
    "                raise ValueError\n",
    "            try:\n",
    "                star_rating = float(driver.find_element(By.ID,'acrPopover').get_attribute('title').split(\" \")[0])\n",
    "                if star_rating < 0 or star_rating > 5:\n",
    "                    logging.critical(f\"star rating messed up : {link.ASIN} - {link._1}\")\n",
    "                    raise ValueError\n",
    "            except NoSuchElementException:\n",
    "                logging.info(f\"star rating element was not found : {link.ASIN} - {link._1}\")\n",
    "                is_any_detail_missing = True\n",
    "                missing_details_dict['star_rating'] = True\n",
    "                star_rating = None\n",
    "            try:\n",
    "                ratings = driver.find_element(By.ID,'acrCustomerReviewText').text\n",
    "                ratings = re.sub(r'[^\\d]', '',ratings)\n",
    "                ratings = int(ratings)\n",
    "                if ratings < 0 or (ratings > 0 and star_rating == 0):\n",
    "                    logging.critical(f\"some ratings messed up at index : {link.ASIN} - {link._1}\")\n",
    "                    raise ValueError\n",
    "            except NoSuchElementException:\n",
    "                logging.info(f\"no of ratings element not found : {link.ASIN} - {link._1}\")\n",
    "                is_any_detail_missing = True\n",
    "                missing_details_dict['ratings'] = True\n",
    "                ratings = None\n",
    "            overview = {}\n",
    "            try:\n",
    "                trs = driver.find_element(By.ID,'productOverview_feature_div').find_element(By.TAG_NAME,'table').find_elements(By.TAG_NAME,'tr')\n",
    "                if len(trs) == 0:\n",
    "                    logging.critical(f\"no table rows of overview found : {link.ASIN} - {link._1}\")\n",
    "                    raise ValueError\n",
    "                for tr in trs:\n",
    "                    cells = tr.find_elements(By.TAG_NAME,'td')\n",
    "                    if len(cells) == 2:\n",
    "                        spans_in_first = cells[0].find_elements(By.TAG_NAME,'span')\n",
    "                        spans_in_second = cells[1].find_elements(By.TAG_NAME,'span')\n",
    "                        if len(spans_in_first) == len(spans_in_second) == 1:\n",
    "                            overview[driver.execute_script(\"return arguments[0].textContent\",spans_in_first[0])] = driver.execute_script(\"return arguments[0].textContent\",spans_in_second[0])\n",
    "            except NoSuchElementException:\n",
    "                logging.info(f\"overview feature not found : {link.ASIN} - {link._1}\")\n",
    "                is_any_detail_missing = True\n",
    "                missing_details_dict['Overview'] = True\n",
    "                overview = None\n",
    "            try:\n",
    "                bullets = driver.find_element(By.ID,'feature-bullets').find_element(By.TAG_NAME,'ul').find_elements(By.TAG_NAME,'li')\n",
    "                if len(bullets) == 0:\n",
    "                    logging.critical(f\"no bullets of about this item found : {link.ASIN} - {link._1}\")\n",
    "                    raise ValueError\n",
    "                bullets_text = list()\n",
    "                for bullet in bullets:\n",
    "                    span = bullet.find_element(By.TAG_NAME,'span')\n",
    "                    bullets_text.append(driver.execute_script('return arguments[0].textContent',span))\n",
    "            except NoSuchElementException:\n",
    "                logging.info(f\"bullets was not found : {link.ASIN} - {link._1}\")\n",
    "                is_any_detail_missing = True\n",
    "                missing_details_dict['featureBullets'] = True\n",
    "                bullets_text = None\n",
    "            salePrice = float(re.sub(r'[^\\d.]','',driver.find_element(By.ID,'corePriceDisplay_desktop_feature_div').find_element(By.CSS_SELECTOR,\"span.priceToPay\").find_element(By.CSS_SELECTOR,\"span.a-price-whole\").text))\n",
    "            if salePrice < 0:\n",
    "                logging.critical(f\"sale price messed up : {link.ASIN} - {link._1}\")\n",
    "                raise ValueError\n",
    "            try:\n",
    "                basisPriceElem = driver.find_element(By.ID,'corePriceDisplay_desktop_feature_div').find_element(By.CSS_SELECTOR,\"span.basisPrice\").find_element(By.CSS_SELECTOR,\"span.a-text-price\").find_element(By.TAG_NAME,'span')\n",
    "                basisPrice = driver.execute_script(\"return arguments[0].textContent\",basisPriceElem)\n",
    "                listPrice = float(re.sub(r'[^\\d.]', '',basisPrice))\n",
    "                if listPrice < salePrice:\n",
    "                    logging.critical(f\"listPrice smaller than sale price : {link.ASIN} - {link._1}\")\n",
    "                    raise ValueError\n",
    "            except NoSuchElementException:\n",
    "                logging.info(f'list price was not found : {link.ASIN} - {link._1}')\n",
    "                is_any_detail_missing = True\n",
    "                missing_details_dict['listPrice'] = True\n",
    "                listPrice = None\n",
    "            new_entry = {'ASIN':link.ASIN,'Images':[img_src],'title':title,'productOverview':overview,'featureBullets':bullets_text,'stars':star_rating,'ratings':ratings,'listPrice':listPrice,'salePrice':salePrice}\n",
    "            writer.writerow(new_entry)\n",
    "            file.flush()\n",
    "            if is_any_detail_missing:\n",
    "                missing_details_df = pd.concat([missing_details_df,pd.DataFrame([missing_details_dict])],ignore_index=True)\n",
    "            no_of_items_to_scrape -= 1\n",
    "            if no_of_items_to_scrape == 0:\n",
    "                print(\"breaking normally\")\n",
    "                logging.info(\"-------------------------------------Next Lot Begins-------------------------------------------------------------\")\n",
    "                break\n",
    "            how_many_done_checkpoint += 1\n",
    "            if how_many_done_checkpoint == 100:\n",
    "                missing_details_df.to_csv('MissingDetailsChart.csv',index=False)\n",
    "                print(2000-no_of_items_to_scrape,\"done\")\n",
    "                how_many_done_checkpoint = 0\n",
    "        except ValueError as e:\n",
    "            print(\"value Error occurred , breaking out \",e)\n",
    "            break\n",
    "        except NoSuchElementException:\n",
    "            # print(f\"no such element occurred , blacklisting {link.ASIN}\")\n",
    "            logging.warning(f'Blacklisted asin : {link.ASIN} - {link._1}')\n",
    "            blacklisted_asins.append(link.ASIN)\n",
    "            pd.DataFrame({'blacklisted_asins':blacklisted_asins}).to_csv('Blacklisted_ASINs.csv',index=False)\n",
    "        except Exception as e:\n",
    "            print(\"some exception occurred breaking out\",e)\n",
    "            logging.critical(f'some unexpected exception occurred : {link.ASIN} - {link._1}')\n",
    "            break\n",
    "missing_details_df.to_csv('MissingDetailsChart.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Images'] = df['Images'].apply(lambda x :ast.literal_eval(x))\n",
    "df['productOverview'] = df['productOverview'].apply(lambda x :ast.literal_eval(x))\n",
    "df['featureBullets'] = df['featureBullets'].apply(lambda x :ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Main Category</th>\n",
       "      <th>Tag</th>\n",
       "      <th>ASIN</th>\n",
       "      <th>Product Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baby Products</td>\n",
       "      <td>Diapers</td>\n",
       "      <td>B075GHP2LX</td>\n",
       "      <td>https://www.amazon.in/dp/B075GHP2LX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baby Products</td>\n",
       "      <td>Diapers</td>\n",
       "      <td>B08X3KG1T9</td>\n",
       "      <td>https://www.amazon.in/dp/B08X3KG1T9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baby Products</td>\n",
       "      <td>Diapers</td>\n",
       "      <td>B0D9GX6F1W</td>\n",
       "      <td>https://www.amazon.in/dp/B0D9GX6F1W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baby Products</td>\n",
       "      <td>Diapers</td>\n",
       "      <td>B07DP24NSR</td>\n",
       "      <td>https://www.amazon.in/dp/B07DP24NSR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baby Products</td>\n",
       "      <td>Diapers</td>\n",
       "      <td>B08X3LXQT7</td>\n",
       "      <td>https://www.amazon.in/dp/B08X3LXQT7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7087</th>\n",
       "      <td>Sports &amp; Outdoors</td>\n",
       "      <td>Water Bottles &amp; Shakers</td>\n",
       "      <td>B0BF5YFP1K</td>\n",
       "      <td>https://www.amazon.in/dp/B0BF5YFP1K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7088</th>\n",
       "      <td>Sports &amp; Outdoors</td>\n",
       "      <td>Water Bottles &amp; Shakers</td>\n",
       "      <td>B08Y6Z1TCH</td>\n",
       "      <td>https://www.amazon.in/dp/B08Y6Z1TCH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7089</th>\n",
       "      <td>Sports &amp; Outdoors</td>\n",
       "      <td>Water Bottles &amp; Shakers</td>\n",
       "      <td>B0CKQ2PV14</td>\n",
       "      <td>https://www.amazon.in/dp/B0CKQ2PV14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7090</th>\n",
       "      <td>Sports &amp; Outdoors</td>\n",
       "      <td>Water Bottles &amp; Shakers</td>\n",
       "      <td>B0CQSTXRHN</td>\n",
       "      <td>https://www.amazon.in/dp/B0CQSTXRHN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7091</th>\n",
       "      <td>Sports &amp; Outdoors</td>\n",
       "      <td>Water Bottles &amp; Shakers</td>\n",
       "      <td>B0CRH35ZP3</td>\n",
       "      <td>https://www.amazon.in/dp/B0CRH35ZP3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7092 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Main Category                      Tag        ASIN  \\\n",
       "0         Baby Products                  Diapers  B075GHP2LX   \n",
       "1         Baby Products                  Diapers  B08X3KG1T9   \n",
       "2         Baby Products                  Diapers  B0D9GX6F1W   \n",
       "3         Baby Products                  Diapers  B07DP24NSR   \n",
       "4         Baby Products                  Diapers  B08X3LXQT7   \n",
       "...                 ...                      ...         ...   \n",
       "7087  Sports & Outdoors  Water Bottles & Shakers  B0BF5YFP1K   \n",
       "7088  Sports & Outdoors  Water Bottles & Shakers  B08Y6Z1TCH   \n",
       "7089  Sports & Outdoors  Water Bottles & Shakers  B0CKQ2PV14   \n",
       "7090  Sports & Outdoors  Water Bottles & Shakers  B0CQSTXRHN   \n",
       "7091  Sports & Outdoors  Water Bottles & Shakers  B0CRH35ZP3   \n",
       "\n",
       "                             Product Link  \n",
       "0     https://www.amazon.in/dp/B075GHP2LX  \n",
       "1     https://www.amazon.in/dp/B08X3KG1T9  \n",
       "2     https://www.amazon.in/dp/B0D9GX6F1W  \n",
       "3     https://www.amazon.in/dp/B07DP24NSR  \n",
       "4     https://www.amazon.in/dp/B08X3LXQT7  \n",
       "...                                   ...  \n",
       "7087  https://www.amazon.in/dp/B0BF5YFP1K  \n",
       "7088  https://www.amazon.in/dp/B08Y6Z1TCH  \n",
       "7089  https://www.amazon.in/dp/B0CKQ2PV14  \n",
       "7090  https://www.amazon.in/dp/B0CQSTXRHN  \n",
       "7091  https://www.amazon.in/dp/B0CRH35ZP3  \n",
       "\n",
       "[7092 rows x 4 columns]"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B0DGTRFQTL', 'B0DGTNQ8BD', 'B0DGTQWPTQ', 'B0DC3R87QV', 'B0DJSKND2G']"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "blacklisted_asins"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
