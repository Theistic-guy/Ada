{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import ast\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "logging.basicConfig(\n",
    "    filename='scraping_missing.log',\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_details_df = pd.read_csv('aryaman/csv/scraping/scraping_details.csv',encoding='utf-8')\n",
    "products = pd.read_csv('aryaman/csv/categories_and_products/products.csv')\n",
    "missing_details_df = pd.read_csv(\"aryaman/csv/scraping/MissingDetailsChart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_details_df['Images'] = scraped_details_df['Images'].apply(lambda item: ast.literal_eval(item) if pd.notna(item) else item)\n",
    "scraped_details_df['productOverview'] = scraped_details_df['productOverview'].apply(lambda item: ast.literal_eval(item) if pd.notna(item) else item)\n",
    "scraped_details_df['featureBullets'] = scraped_details_df['featureBullets'].apply(lambda item: ast.literal_eval(item) if pd.notna(item) else item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "featureBullets  Overview\n",
       "False           True        259\n",
       "True            False        67\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bullets_and_overview_same_df = missing_details_df[missing_details_df['featureBullets']== missing_details_df['Overview']]\n",
    "diff_bullets_and_overview_df = pd.concat([bullets_and_overview_same_df,missing_details_df]).drop_duplicates(keep=False)\n",
    "diff_bullets_and_overview_df[['featureBullets','Overview']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(products,missing_details_df[(missing_details_df['featureBullets']==True) & (missing_details_df['Overview']==True)],on='ASIN',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "webdriver_path = \"..\\chromedriver.exe\"\n",
    "cService = webdriver.ChromeService(executable_path=webdriver_path)\n",
    "# chrome_options = Options()\n",
    "# chrome_options.add_experimental_option(\"detach\",True)\n",
    "driver = webdriver.Chrome(service=cService)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('scraping_missing_details_featureBullets_Overview.csv','w',newline='',encoding='utf-8') as file:\n",
    "#     writer = csv.DictWriter(file,fieldnames=['ASIN',  'productOverview', 'featureBullets'])\n",
    "#     writer.writeheader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({\"blacklisted_asins\":[]}).to_csv('blacklisted2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_unscraped_iter(products_links_df,scraped_details_df):\n",
    "    return list(products_links_df[~(products_links_df['ASIN'].isin(scraped_details_df['ASIN']))].itertuples(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_missing_details_df = pd.read_csv('scraping_missing_details_featureBullets_Overview.csv',encoding='utf-8')\n",
    "products_links = merged_df[['ASIN','Product Link']]\n",
    "products_links.reset_index(inplace=True,drop=True)\n",
    "blacklisted_asins = (pd.read_csv('blacklisted2.csv'))['blacklisted_asins'].tolist()\n",
    "missing_details_update_df = pd.read_csv(\"MissingDetailsUpdated.csv\")\n",
    "no_of_items_to_scrape = 1000\n",
    "how_many_scraped = 0\n",
    "with open('scraping_missing_details_featureBullets_Overview.csv','a',newline='',encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file,fieldnames=['ASIN','productOverview','featureBullets'])\n",
    "    iterator_to_loop = filter_unscraped_iter(products_links,scraped_missing_details_df)\n",
    "    for link in iterator_to_loop:\n",
    "        if link.ASIN in blacklisted_asins:\n",
    "            continue\n",
    "        driver.get(link._1)\n",
    "        time.sleep(1)\n",
    "        try:\n",
    "            productFactsDiv = driver.find_element(By.ID,'productFactsDesktop_feature_div')\n",
    "            try:\n",
    "                overview = dict()\n",
    "                headings = productFactsDiv.find_elements(By.TAG_NAME,'h3')\n",
    "                product_details_heading = None\n",
    "                for heading in headings:\n",
    "                    if ((driver.execute_script(\"return arguments[0].textContent\",heading)).strip() == 'Product details'):\n",
    "                        product_details_heading = heading\n",
    "                if product_details_heading != None:\n",
    "                    missing_details_update_df.loc[missing_details_update_df['ASIN']==link.ASIN,'Overview'] =  False\n",
    "                    logging.info(f\"missing details updated {link.ASIN}\")\n",
    "                    nextSibling = driver.execute_script(\"return arguments[0].nextElementSibling\",product_details_heading)\n",
    "                    while( nextSibling.tag_name == 'div' and 'product-facts-detail' in nextSibling.get_attribute(\"class\")):\n",
    "                        spans = nextSibling.find_elements(By.CSS_SELECTOR,\"span.a-color-base\")\n",
    "                        if len(spans) == 2:\n",
    "                            if len(spans[0].find_elements(By.CSS_SELECTOR,\"*\")) == len(spans[1].find_elements(By.CSS_SELECTOR,\"*\")) == 0:\n",
    "                                overview[driver.execute_script(\"return arguments[0].textContent\",spans[0])] = driver.execute_script(\"return arguments[0].textContent\",spans[1])\n",
    "                        nextSibling = driver.execute_script(\"return arguments[0].nextElementSibling\",nextSibling)\n",
    "            except NoSuchElementException:\n",
    "                print(\"over view not found\",link.ASIN)\n",
    "                logging.info(f\"overview not found {link.ASIN}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Exception in headings {link.ASIN}\",e)\n",
    "                break\n",
    "            try:\n",
    "                bullets_text = list()\n",
    "                list_of_bullets = productFactsDiv.find_element(By.TAG_NAME,'ul')\n",
    "                bullets = list_of_bullets.find_elements(By.TAG_NAME,'li')\n",
    "                if len(bullets) == 0:\n",
    "                    raise ValueError\n",
    "                missing_details_update_df.loc[missing_details_update_df['ASIN']==link.ASIN,'featureBullets'] =  False\n",
    "                logging.info(f\"missing details updated {link.ASIN}\")\n",
    "                for bullet in bullets:\n",
    "                    spans = bullet.find_elements(By.TAG_NAME,'span')\n",
    "                    if len(spans) == 1:\n",
    "                        if len(spans[0].find_elements(By.CSS_SELECTOR,\"*\")) == 0:\n",
    "                            bullets_text.append((driver.execute_script(\"return arguments[0].textContent\",spans[0])))\n",
    "                \n",
    "            except NoSuchElementException:\n",
    "                print(\"bullets not found \",link.ASIN)\n",
    "                logging.info(f\"bullets not found {link.ASIN}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Exception in bullets {link.ASIN}\",e)\n",
    "                break\n",
    "            if len(overview)>0 or len(bullets_text) > 0:\n",
    "                if len(overview) == 0:\n",
    "                    overview = None\n",
    "                if len(bullets_text) == 0:\n",
    "                    bullets_text = None\n",
    "                new_entry = {'ASIN':link.ASIN,'productOverview':overview,'featureBullets':bullets_text}\n",
    "                writer.writerow(new_entry)\n",
    "                file.flush()\n",
    "            missing_details_update_df.to_csv('MissingDetailsUpdated.csv',index=False)\n",
    "            no_of_items_to_scrape -= 1\n",
    "            if no_of_items_to_scrape == 0:\n",
    "                print('break normally')\n",
    "                break\n",
    "            how_many_scraped += 1\n",
    "            if how_many_scraped == 50:\n",
    "                print(1000-no_of_items_to_scrape)\n",
    "                how_many_scraped = 0\n",
    "            \n",
    "        except ValueError as e:\n",
    "            print(f\"value error occurred,breaking {link.ASIN}\",e)\n",
    "            break\n",
    "        except NoSuchElementException:\n",
    "            # print(\"Blacklisting\")\n",
    "            blacklisted_asins.append(link.ASIN)\n",
    "            pd.DataFrame({'blacklisted_asins':blacklisted_asins}).to_csv('blacklisted2.csv',index=False)\n",
    "            logging.warning(f\"blacklisted - {link.ASIN}\")\n",
    "        except Exception as e:\n",
    "            print(f\"some exception occurred,breaking {link.ASIN}\",e)\n",
    "            break\n",
    "missing_details_update_df.to_csv('MissingDetailsUpdated.csv',index=False)\n",
    "logging.info(f\"missing details flushed to file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
