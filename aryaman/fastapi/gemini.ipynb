{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "60e4cc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "import google.generativeai as genai\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eeb746",
   "metadata": {},
   "source": [
    "# Pre-Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ab668796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\aryam\\\\Documents\\\\ML\\\\Ada_E_Comm\\\\Ada'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "97e4b1d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mprin\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prin' is not defined"
     ]
    }
   ],
   "source": [
    "prin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a064ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json('Final_Dataset_JSON.json',encoding='utf-8',orient='records')  comment to keep it safe from running again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9826ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6629 entries, 0 to 6628\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Main Category    6629 non-null   object \n",
      " 1   Tag              6629 non-null   object \n",
      " 2   ASIN             6629 non-null   object \n",
      " 3   Product Link     6629 non-null   object \n",
      " 4   Images           6629 non-null   object \n",
      " 5   title            6629 non-null   object \n",
      " 6   productOverview  5674 non-null   object \n",
      " 7   featureBullets   5878 non-null   object \n",
      " 8   stars            6356 non-null   float64\n",
      " 9   ratings          6356 non-null   float64\n",
      " 10  listPrice        6288 non-null   float64\n",
      " 11  salePrice        6629 non-null   int64  \n",
      " 12  bookDescription  647 non-null    object \n",
      "dtypes: float64(3), int64(1), object(9)\n",
      "memory usage: 673.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac8bdea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Main Category', 'Tag', 'ASIN', 'Product Link', 'Images', 'title',\n",
       "       'productOverview', 'featureBullets', 'stars', 'ratings', 'listPrice',\n",
       "       'salePrice', 'bookDescription'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234a4961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Main Category         0\n",
       "Tag                   0\n",
       "ASIN                  0\n",
       "Product Link          0\n",
       "Images                0\n",
       "title                 0\n",
       "productOverview     955\n",
       "featureBullets      751\n",
       "stars               273\n",
       "ratings             273\n",
       "listPrice           341\n",
       "salePrice             0\n",
       "bookDescription    5982\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca785d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df[~df['productOverview'].isna()]['productOverview'].apply(lambda x : True if isinstance(x,dict) else False)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0de717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df[~df['featureBullets'].isna()]['featureBullets'].apply(lambda x : True if isinstance(x,list) else False)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcedfe86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df[~df['bookDescription'].isna()]['Main Category'] == 'Books').all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b36019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6629"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['ASIN'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eba9c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts = []  comment to keep it safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719980ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# I have commented the code below to make it un-runable\n",
    "\n",
    "# for _, row in df.iterrows():\n",
    "#     main_cat = row['Main Category']\n",
    "#     tag = row['Tag']\n",
    "#     title = row['title']\n",
    "#     asin = row['ASIN']\n",
    "#     overview = row['productOverview']\n",
    "#     features = row['featureBullets']\n",
    "#     stars = row['stars']\n",
    "#     ratings = row['ratings']\n",
    "#     listprice = row['listPrice']\n",
    "#     saleprice = row['salePrice']\n",
    "#     bookdescription = row['bookDescription']\n",
    "\n",
    "#     parts = []\n",
    "#     parts.append(f\"Top Category of the product : {main_cat}\")\n",
    "#     parts.append(f\"Sub-Category of the product : {tag}\")\n",
    "#     parts.append(f\"Title of the product : {title}\")\n",
    "#     parts.append(f\"ASIN Id of the product : {asin}\")\n",
    "    \n",
    "#     if overview:\n",
    "#         for j in overview:\n",
    "#             parts.append(f\"{j} : {overview[j]}\")\n",
    "\n",
    "#     if features:\n",
    "#         parts.append(f\"Features : {' '.join(features)}\")\n",
    "\n",
    "#     if stars:\n",
    "#         parts.append(f\"Stars given by Users : {stars}\")\n",
    "\n",
    "#     if ratings:\n",
    "#         parts.append(f\"Ratings given by Users : {ratings}\")\n",
    "\n",
    "#     if listprice:\n",
    "#         parts.append(f\"List Price of the product : {listprice}\")\n",
    "\n",
    "#     parts.append(f\"Sale Price of the product : {saleprice}\")\n",
    "\n",
    "#     if bookdescription:\n",
    "#         parts.append(f\"Description of the Book : {bookdescription}\")\n",
    "\n",
    "#     text = \"\\n\".join(parts)\n",
    "\n",
    "#     texts.append(text)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fc5bfeb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6629"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a673db32",
   "metadata": {},
   "source": [
    "# Generating Vector Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec216b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import streamlit as st\n",
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "from config import process_pdf\n",
    "\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "\n",
    "\n",
    "def user_input(user_question):\n",
    "        embeddings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\")\n",
    "        \n",
    "        new_db = FAISS.load_local(\"faiss_index\", embeddings,allow_dangerous_deserialization=True)\n",
    "        docs = new_db.similarity_search(user_question)\n",
    "\n",
    "        chain = process_pdf.get_conversational_chain()\n",
    "\n",
    "        \n",
    "        response = chain(\n",
    "            {\"input_documents\":docs, \"question\": user_question}\n",
    "            , return_only_outputs=True)\n",
    "\n",
    "        print(response)\n",
    "        st.write(\"Reply: \", response[\"output_text\"])\n",
    "\n",
    "\n",
    "def main():\n",
    "    st.set_page_config(\"PDF Q&A Chatbot\", page_icon = \":scroll:\")\n",
    "    st.header(\"PDF📚 - Chat BOt 🤖 \")\n",
    "\n",
    "    user_question = st.text_input(\"Ask Question from the PDF Files uploaded .. ✍️📝\")\n",
    "\n",
    "    if user_question:\n",
    "        user_input(user_question)\n",
    "\n",
    "    with st.sidebar:\n",
    "\n",
    "        st.image(\"logo.jpg\")\n",
    "        st.write(\"---\")\n",
    "        \n",
    "        st.title(\"📁 PDF File's Section\")\n",
    "        pdf_docs = st.file_uploader(\"Upload your PDF Files & \\n Click on the Submit Button \", accept_multiple_files=True)\n",
    "        if st.button(\"Submit\"):\n",
    "            with st.spinner(\"Processing...\"): # user friendly message.\n",
    "                raw_text = process_pdf.get_pdf_text(pdf_docs) # get the pdf text\n",
    "                text_chunks = process_pdf.get_text_chunks(raw_text) # get the text chunks\n",
    "                process_pdf.get_vector_store(text_chunks) # create vector store\n",
    "                st.success(\"Done\")\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4256cfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\")\n",
    "vector_store = FAISS.from_texts(texts, embedding=embeddings)\n",
    "vector_store.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "25383937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.generativeai import GenerativeModel\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "06566f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001 -> ['generateMessage', 'countMessageTokens']\n",
      "models/text-bison-001 -> ['generateText', 'countTextTokens', 'createTunedTextModel']\n",
      "models/embedding-gecko-001 -> ['embedText', 'countTextTokens']\n",
      "models/gemini-1.0-pro-vision-latest -> ['generateContent', 'countTokens']\n",
      "models/gemini-pro-vision -> ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-pro-latest -> ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-pro-001 -> ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-1.5-pro-002 -> ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-1.5-pro -> ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-latest -> ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-001 -> ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-1.5-flash-001-tuning -> ['generateContent', 'countTokens', 'createTunedModel']\n",
      "models/gemini-1.5-flash -> ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-002 -> ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-1.5-flash-8b -> ['createCachedContent', 'generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-8b-001 -> ['createCachedContent', 'generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-8b-latest -> ['createCachedContent', 'generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-8b-exp-0827 -> ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-8b-exp-0924 -> ['generateContent', 'countTokens']\n",
      "models/gemini-2.5-pro-exp-03-25 -> ['generateContent', 'countTokens']\n",
      "models/gemini-2.5-pro-preview-03-25 -> ['generateContent', 'countTokens']\n",
      "models/gemini-2.0-flash-exp -> ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.0-flash -> ['generateContent', 'countTokens']\n",
      "models/gemini-2.0-flash-001 -> ['generateContent', 'countTokens']\n",
      "models/gemini-2.0-flash-exp-image-generation -> ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.0-flash-lite-001 -> ['generateContent', 'countTokens']\n",
      "models/gemini-2.0-flash-lite -> ['generateContent', 'countTokens']\n",
      "models/gemini-2.0-flash-lite-preview-02-05 -> ['generateContent', 'countTokens']\n",
      "models/gemini-2.0-flash-lite-preview -> ['generateContent', 'countTokens']\n",
      "models/gemini-2.0-pro-exp -> ['generateContent', 'countTokens']\n",
      "models/gemini-2.0-pro-exp-02-05 -> ['generateContent', 'countTokens']\n",
      "models/gemini-exp-1206 -> ['generateContent', 'countTokens']\n",
      "models/gemini-2.0-flash-thinking-exp-01-21 -> ['generateContent', 'countTokens']\n",
      "models/gemini-2.0-flash-thinking-exp -> ['generateContent', 'countTokens']\n",
      "models/gemini-2.0-flash-thinking-exp-1219 -> ['generateContent', 'countTokens']\n",
      "models/learnlm-1.5-pro-experimental -> ['generateContent', 'countTokens']\n",
      "models/gemma-3-1b-it -> ['generateContent', 'countTokens']\n",
      "models/gemma-3-4b-it -> ['generateContent', 'countTokens']\n",
      "models/gemma-3-12b-it -> ['generateContent', 'countTokens']\n",
      "models/gemma-3-27b-it -> ['generateContent', 'countTokens']\n",
      "models/embedding-001 -> ['embedContent']\n",
      "models/text-embedding-004 -> ['embedContent']\n",
      "models/gemini-embedding-exp-03-07 -> ['embedContent']\n",
      "models/gemini-embedding-exp -> ['embedContent']\n",
      "models/aqa -> ['generateAnswer']\n",
      "models/imagen-3.0-generate-002 -> ['predict']\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "    print(m.name, \"->\", m.supported_generation_methods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0f6272c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'prompt_searching.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_searching.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      2\u001b[0m     f\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32mc:\\Users\\aryam\\Documents\\ML\\Ada_E_Comm\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'prompt_searching.txt'"
     ]
    }
   ],
   "source": [
    "with open(\"prompt_searching.txt\",\"r\") as f:\n",
    "    f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f119577e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a product filtering assistant.\n",
      "\n",
      "    A user has searched for: \"1\"\n",
      "\n",
      "    Below is a list of products retrieved as similar to the user's query. Each product includes an ASIN and its properties in the format \"property_name: property_value\".\n",
      "\n",
      "    Your task is to:\n",
      "    1. Analyze the user's query and the provided products.\n",
      "    2. Return:\n",
      "    - A JSON list of ASINs for the products that best match the user's intent.\n",
      "    - A short explanation (1-2 sentences) describing why these products were selected, based on the query and product properties.\n",
      "\n",
      "    Respond in the following **strict** JSON format:\n",
      "    {\n",
      "    \"asins\": [\"ASIN1\", \"ASIN2\", \"...\"],\n",
      "    \"explanation\": \"Short explanation here\"\n",
      "    }\n",
      "\n",
      "    Example:\n",
      "    If the user_query is \"rainy shoes\", and among the products there are waterproof boots and slip-resistant sandals, then your response could be:\n",
      "    {\n",
      "    \"asins\": [\"B08XYZ123\", \"B09RAINY456\"],\n",
      "    \"explanation\": \"These products are waterproof and slip-resistant, which makes them suitable for rainy conditions, matching your search for 'rainy shoes'.\"\n",
      "    }\n",
      "\n",
      "    Rules:\n",
      "    - Only include products that are clearly relevant.\n",
      "    - If no relevant products are found, return an empty ASIN list with a suitable explanation.\n",
      "    - Do NOT include anything outside of the JSON object.\n",
      "\n",
      "    Here are the products:\n",
      "    2\n"
     ]
    }
   ],
   "source": [
    "with open(r'C:\\Users\\aryam\\Documents\\ML\\Ada_E_Comm\\Ada\\aryaman\\fastapi\\prompt_searching.txt',\"r\") as f:\n",
    "    str1 = f.read()\n",
    "    print(str1.format(user_query=1,products=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41b4dc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "dict1 = {'h':1}\n",
    "for key,value in dict1.items():\n",
    "    print(key)\n",
    "    print(value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
